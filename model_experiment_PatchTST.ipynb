{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eghib22/Store-Sales-Forecasting/blob/main/model_experiment_PatchTST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1HPsAmGXy2E",
        "outputId": "8a2d5108-b19c-47ad-a143-de597ce96294",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.6.15)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.20.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (24.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.6.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle\n",
        "! pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TkCVhuaYIXT",
        "outputId": "8bc533cd-31d5-4ffe-94c3-7d7ece84774f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "cJoCWUAqYMf2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "qybR_XwZbbiu",
        "outputId": "9a3a4be0-a915-467a-e19f-64c99cc6d7e8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-57b35be4-4014-48bf-8b39-e79205a3dedc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-57b35be4-4014-48bf-8b39-e79205a3dedc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ekaterineghibradze\",\"key\":\"b1414052fbae86987efff2083c8dcbd1\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"kaggle.json\" ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "D1kbLG2Pb9lE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l ~/.kaggle/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtNbrtCycvO7",
        "outputId": "de65b9b9-0449-4582-e225-b3aa72df5cca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4\n",
            "-rw------- 1 root root 74 Jul  6 14:37 kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c walmart-recruiting-store-sales-forecasting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN4023PLZ-1I",
        "outputId": "c1031e74-e866-4605-96f7-f95f411e567c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading walmart-recruiting-store-sales-forecasting.zip to /content\n",
            "\r  0% 0.00/2.70M [00:00<?, ?B/s]\n",
            "\r100% 2.70M/2.70M [00:00<00:00, 896MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip walmart-recruiting-store-sales-forecasting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNg-36PMbu7W",
        "outputId": "ea800560-b787-40e8-e875-be0fa4a44833"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  walmart-recruiting-store-sales-forecasting.zip\n",
            "  inflating: features.csv.zip        \n",
            "  inflating: sampleSubmission.csv.zip  \n",
            "  inflating: stores.csv              \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: train.csv.zip           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '*.csv.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGHVXffUeA_V",
        "outputId": "19fd9f16-3e4d-4ffb-b596-d210180983a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "\n",
            "Archive:  features.csv.zip\n",
            "  inflating: features.csv            \n",
            "\n",
            "Archive:  sampleSubmission.csv.zip\n",
            "  inflating: sampleSubmission.csv    \n",
            "\n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "\n",
            "4 archives were successfully processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '*.csv.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpflLFtWeQpt",
        "outputId": "0a2c9487-067b-4cf2-8edf-d93cdc8801c7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  test.csv.zip\n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: test.csv                \n",
            "\n",
            "Archive:  features.csv.zip\n",
            "replace features.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: features.csv            \n",
            "\n",
            "Archive:  sampleSubmission.csv.zip\n",
            "replace sampleSubmission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: sampleSubmission.csv    \n",
            "\n",
            "Archive:  train.csv.zip\n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: train.csv               \n",
            "\n",
            "4 archives were successfully processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "features = pd.read_csv('features.csv')\n",
        "stores = pd.read_csv('stores.csv')\n",
        "sample_submission = pd.read_csv('sampleSubmission.csv')\n",
        "\n",
        "# Explore the data\n",
        "print(\"Train shape:\", train.shape)\n",
        "print(train.head())\n",
        "print(train.columns)\n",
        "\n",
        "print(\"\\nTest shape:\", test.shape)\n",
        "print(test.head())\n",
        "print(test.columns)\n",
        "\n",
        "print(\"\\nFeatures shape:\", features.shape)\n",
        "print(features.head())\n",
        "print(features.columns)\n",
        "\n",
        "print(\"\\nStores shape:\", stores.shape)\n",
        "print(stores.head())\n",
        "print(stores.columns)\n",
        "\n",
        "print(\"\\nSample Submission shape:\", sample_submission.shape)\n",
        "print(sample_submission.head())\n",
        "print(sample_submission.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZpgC7NMjecK",
        "outputId": "11129305-64b9-403b-f95a-8ee585f08b48",
        "collapsed": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (421570, 5)\n",
            "   Store  Dept        Date  Weekly_Sales  IsHoliday\n",
            "0      1     1  2010-02-05      24924.50      False\n",
            "1      1     1  2010-02-12      46039.49       True\n",
            "2      1     1  2010-02-19      41595.55      False\n",
            "3      1     1  2010-02-26      19403.54      False\n",
            "4      1     1  2010-03-05      21827.90      False\n",
            "Index(['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday'], dtype='object')\n",
            "\n",
            "Test shape: (115064, 4)\n",
            "   Store  Dept        Date  IsHoliday\n",
            "0      1     1  2012-11-02      False\n",
            "1      1     1  2012-11-09      False\n",
            "2      1     1  2012-11-16      False\n",
            "3      1     1  2012-11-23       True\n",
            "4      1     1  2012-11-30      False\n",
            "Index(['Store', 'Dept', 'Date', 'IsHoliday'], dtype='object')\n",
            "\n",
            "Features shape: (8190, 12)\n",
            "   Store        Date  Temperature  Fuel_Price  MarkDown1  MarkDown2  \\\n",
            "0      1  2010-02-05        42.31       2.572        NaN        NaN   \n",
            "1      1  2010-02-12        38.51       2.548        NaN        NaN   \n",
            "2      1  2010-02-19        39.93       2.514        NaN        NaN   \n",
            "3      1  2010-02-26        46.63       2.561        NaN        NaN   \n",
            "4      1  2010-03-05        46.50       2.625        NaN        NaN   \n",
            "\n",
            "   MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
            "0        NaN        NaN        NaN  211.096358         8.106      False  \n",
            "1        NaN        NaN        NaN  211.242170         8.106       True  \n",
            "2        NaN        NaN        NaN  211.289143         8.106      False  \n",
            "3        NaN        NaN        NaN  211.319643         8.106      False  \n",
            "4        NaN        NaN        NaN  211.350143         8.106      False  \n",
            "Index(['Store', 'Date', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2',\n",
            "       'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment',\n",
            "       'IsHoliday'],\n",
            "      dtype='object')\n",
            "\n",
            "Stores shape: (45, 3)\n",
            "   Store Type    Size\n",
            "0      1    A  151315\n",
            "1      2    A  202307\n",
            "2      3    B   37392\n",
            "3      4    A  205863\n",
            "4      5    B   34875\n",
            "Index(['Store', 'Type', 'Size'], dtype='object')\n",
            "\n",
            "Sample Submission shape: (115064, 2)\n",
            "               Id  Weekly_Sales\n",
            "0  1_1_2012-11-02             0\n",
            "1  1_1_2012-11-09             0\n",
            "2  1_1_2012-11-16             0\n",
            "3  1_1_2012-11-23             0\n",
            "4  1_1_2012-11-30             0\n",
            "Index(['Id', 'Weekly_Sales'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge train and test with features and stores\n",
        "train_merged = pd.merge(train, features, on=['Store', 'Date'], how='left')\n",
        "train_merged = pd.merge(train_merged, stores, on='Store', how='left')\n",
        "\n",
        "test_merged = pd.merge(test, features, on=['Store', 'Date'], how='left')\n",
        "test_merged = pd.merge(test_merged, stores, on='Store', how='left')\n",
        "\n",
        "# Convert Date to datetime\n",
        "train_merged['Date'] = pd.to_datetime(train_merged['Date'])\n"
      ],
      "metadata": {
        "id": "GznCjGNPkKZ7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split\n",
        "train_data = train_merged[train_merged['Date'] < '2012-01-01']\n",
        "val_data = train_merged[(train_merged['Date'] >= '2012-01-01') & (train_merged['Date'] < '2012-07-01')]\n",
        "test_data = train_merged[train_merged['Date'] >= '2012-07-01']\n",
        "\n",
        "print(\"Train:\", train_data.shape)\n",
        "print(\"Validation:\", val_data.shape)\n",
        "print(\"Test (local):\", test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQnvIhe4lnEZ",
        "outputId": "02bf3eb1-fdad-439f-f701-aefc092d64be"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (294132, 17)\n",
            "Validation: (77110, 17)\n",
            "Test (local): (50328, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "wandb.init(project=\"Store-Sales-Forecasting\", entity=\"agasi22-free-university-of-tbilisi-\" , name=\"patchTST-training-run\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "-xGq20oYx3qw",
        "outputId": "0f8c8e50-8081-462b-a463-3470fd2ea642"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meghib22\u001b[0m (\u001b[33meghib22-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250706_143732-0kd53o2j</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/agasi22-free-university-of-tbilisi-/Store-Sales-Forecasting/runs/0kd53o2j' target=\"_blank\">patchTST-training-run</a></strong> to <a href='https://wandb.ai/agasi22-free-university-of-tbilisi-/Store-Sales-Forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/agasi22-free-university-of-tbilisi-/Store-Sales-Forecasting' target=\"_blank\">https://wandb.ai/agasi22-free-university-of-tbilisi-/Store-Sales-Forecasting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/agasi22-free-university-of-tbilisi-/Store-Sales-Forecasting/runs/0kd53o2j' target=\"_blank\">https://wandb.ai/agasi22-free-university-of-tbilisi-/Store-Sales-Forecasting/runs/0kd53o2j</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/agasi22-free-university-of-tbilisi-/Store-Sales-Forecasting/runs/0kd53o2j?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7efc78f7b790>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Encode 'Type' categorical\n",
        "    if 'Type' in df.columns:\n",
        "        type_map = {'A': 0, 'B': 1, 'C': 2}\n",
        "        df['Type'] = df['Type'].map(type_map)\n",
        "\n",
        "    # Handle IsHoliday columns robustly\n",
        "    if 'IsHoliday_x' in df.columns and 'IsHoliday_y' in df.columns:\n",
        "        df['IsHoliday'] = df['IsHoliday_x'].fillna(0).astype(int)\n",
        "        df = df.drop(columns=['IsHoliday_x', 'IsHoliday_y'])\n",
        "    elif 'IsHoliday_x' in df.columns:\n",
        "        df['IsHoliday'] = df['IsHoliday_x'].fillna(0).astype(int)\n",
        "        df = df.drop(columns=['IsHoliday_x'])\n",
        "    elif 'IsHoliday_y' in df.columns:\n",
        "        df['IsHoliday'] = df['IsHoliday_y'].fillna(0).astype(int)\n",
        "        df = df.drop(columns=['IsHoliday_y'])\n",
        "    elif 'IsHoliday' in df.columns:\n",
        "        df['IsHoliday'] = df['IsHoliday'].fillna(0).astype(int)\n",
        "    else:\n",
        "        # No IsHoliday column at all — create one with zeros\n",
        "        df['IsHoliday'] = 0\n",
        "\n",
        "    # Ensure Date is datetime type\n",
        "    if 'Date' in df.columns and not pd.api.types.is_datetime64_any_dtype(df['Date']):\n",
        "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "\n",
        "    # Extract date features only if Date column exists\n",
        "    if 'Date' in df.columns:\n",
        "        df['Year'] = df['Date'].dt.year\n",
        "        df['Month'] = df['Date'].dt.month\n",
        "        df['Week'] = df['Date'].dt.isocalendar().week\n",
        "        df['Day'] = df['Date'].dt.day\n",
        "        df = df.drop(columns=['Date'])\n",
        "\n",
        "    # Fill MarkDown NaNs safely\n",
        "    markdown_cols = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
        "    for col in markdown_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].fillna(0)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Preprocess train and val\n",
        "train_data_processed = preprocess(train_data)\n",
        "val_data_processed = preprocess(val_data)\n",
        "\n",
        "# Example weights for WMAE:\n",
        "weights_val = val_data_processed['IsHoliday'].apply(lambda x: 5 if x == 1 else 1)"
      ],
      "metadata": {
        "id": "vb3wF8lEL135"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import wandb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "\n",
        "class PatchTST(nn.Module):\n",
        "    def __init__(self, n_vars, patch_len, stride, d_model, n_heads, n_layers, d_ff, dropout=0.1):\n",
        "        super(PatchTST, self).__init__()\n",
        "\n",
        "        self.n_vars = n_vars\n",
        "        self.patch_len = patch_len\n",
        "        self.stride = stride\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Patch embedding layer\n",
        "        self.patch_embedding = nn.Linear(patch_len, d_model)\n",
        "\n",
        "        # Positional encoding\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(1000, d_model))\n",
        "\n",
        "        # Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=d_ff,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "\n",
        "        # Output projection\n",
        "        self.output_projection = nn.Linear(d_model, 1)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def create_patches(self, x):\n",
        "        # x shape: (batch_size, seq_len, n_vars)\n",
        "        batch_size, seq_len, n_vars = x.shape\n",
        "\n",
        "        # Create patches for each variable\n",
        "        patches = []\n",
        "        for i in range(n_vars):\n",
        "            var_data = x[:, :, i]  # (batch_size, seq_len)\n",
        "            var_patches = []\n",
        "\n",
        "            # Create patches with stride\n",
        "            for start in range(0, seq_len - self.patch_len + 1, self.stride):\n",
        "                end = start + self.patch_len\n",
        "                patch = var_data[:, start:end]  # (batch_size, patch_len)\n",
        "                var_patches.append(patch)\n",
        "\n",
        "            if var_patches:\n",
        "                var_patches = torch.stack(var_patches, dim=1)  # (batch_size, n_patches, patch_len)\n",
        "                patches.append(var_patches)\n",
        "\n",
        "        if patches:\n",
        "            patches = torch.cat(patches, dim=1)  # (batch_size, n_vars * n_patches, patch_len)\n",
        "        else:\n",
        "            # Fallback if no patches could be created\n",
        "            patches = torch.zeros(batch_size, 1, self.patch_len, device=x.device)\n",
        "\n",
        "        return patches\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Create patches\n",
        "        patches = self.create_patches(x)  # (batch_size, n_patches, patch_len)\n",
        "        batch_size, n_patches, _ = patches.shape\n",
        "\n",
        "        # Embed patches\n",
        "        embedded = self.patch_embedding(patches)  # (batch_size, n_patches, d_model)\n",
        "\n",
        "        # Add positional encoding\n",
        "        pos_enc = self.positional_encoding[:n_patches, :].unsqueeze(0).expand(batch_size, -1, -1)\n",
        "        embedded = embedded + pos_enc\n",
        "\n",
        "        # Apply dropout\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        # Pass through transformer\n",
        "        transformer_out = self.transformer(embedded)  # (batch_size, n_patches, d_model)\n",
        "\n",
        "        # Global average pooling\n",
        "        pooled = transformer_out.mean(dim=1)  # (batch_size, d_model)\n",
        "\n",
        "        # Output projection\n",
        "        output = self.output_projection(pooled)  # (batch_size, 1)\n",
        "\n",
        "        return output.squeeze(-1)  # (batch_size,)\n",
        "\n",
        "def create_sequences(df, seq_len=52, target_col='Weekly_Sales'):\n",
        "    \"\"\"Create sequences for time series prediction\"\"\"\n",
        "    sequences = []\n",
        "    targets = []\n",
        "\n",
        "    # Group by store to maintain temporal order within each store\n",
        "    for store in df['Store'].unique():\n",
        "        store_data = df[df['Store'] == store].sort_values('Year').reset_index(drop=True)\n",
        "\n",
        "        if len(store_data) < seq_len + 1:\n",
        "            continue\n",
        "\n",
        "        # Select relevant features (excluding target and store ID)\n",
        "        feature_cols = [col for col in store_data.columns if col not in ['Weekly_Sales', 'Store']]\n",
        "        store_features = store_data[feature_cols].values\n",
        "        store_targets = store_data[target_col].values\n",
        "\n",
        "        # Create sequences\n",
        "        for i in range(len(store_data) - seq_len):\n",
        "            seq = store_features[i:i + seq_len]\n",
        "            target = store_targets[i + seq_len]\n",
        "            sequences.append(seq)\n",
        "            targets.append(target)\n",
        "\n",
        "    return np.array(sequences), np.array(targets)\n",
        "\n",
        "def calculate_wmae(y_true, y_pred, weights):\n",
        "    \"\"\"Calculate Weighted Mean Absolute Error\"\"\"\n",
        "    mae = np.abs(y_true - y_pred)\n",
        "    wmae = np.sum(weights * mae) / np.sum(weights)\n",
        "    return wmae\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=50, lr=0.001, device='cpu'):\n",
        "    \"\"\"Train the PatchTST model\"\"\"\n",
        "    model = model.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # Watch model for wandb\n",
        "    wandb.watch(model, log='all', log_freq=10)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_x, batch_y in val_loader:\n",
        "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "                outputs = model(batch_x)\n",
        "                loss = criterion(outputs, batch_y)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Log metrics to wandb\n",
        "        wandb.log({\n",
        "            'epoch': epoch,\n",
        "            'train_loss': avg_train_loss,\n",
        "            'val_loss': avg_val_loss,\n",
        "            'learning_rate': optimizer.param_groups[0]['lr']\n",
        "        })\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            best_model_state = model.state_dict().copy()\n",
        "\n",
        "            # Log best validation loss\n",
        "            wandb.log({'best_val_loss': best_val_loss})\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch [{epoch}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(best_model_state)\n",
        "    return model\n",
        "\n",
        "def main():\n",
        "    # Initialize wandb\n",
        "    wandb.init(\n",
        "        project=\"store-sales-prediction\",\n",
        "        name=\"PatchTST\",\n",
        "        config={\n",
        "            \"model\": \"PatchTST\",\n",
        "            \"seq_len\": 52,\n",
        "            \"batch_size\": 32,\n",
        "            \"patch_len\": 4,\n",
        "            \"stride\": 2,\n",
        "            \"d_model\": 64,\n",
        "            \"n_heads\": 4,\n",
        "            \"n_layers\": 2,\n",
        "            \"d_ff\": 128,\n",
        "            \"dropout\": 0.1,\n",
        "            \"learning_rate\": 0.001,\n",
        "            \"num_epochs\": 50,\n",
        "            \"optimizer\": \"Adam\",\n",
        "            \"loss_function\": \"MSE\",\n",
        "            \"scheduler\": \"ReduceLROnPlateau\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Load and preprocess data (using your existing code)\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "\n",
        "    # Your existing data loading and preprocessing code would go here\n",
        "    # For this example, I'll assume the data is already loaded as per your code\n",
        "\n",
        "    # Parameters\n",
        "    seq_len = wandb.config.seq_len\n",
        "    batch_size = wandb.config.batch_size\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Log device info\n",
        "    wandb.log({\"device\": str(device)})\n",
        "\n",
        "    # Create sequences\n",
        "    print(\"Creating sequences...\")\n",
        "    X_train, y_train = create_sequences(train_data_processed, seq_len)\n",
        "    X_val, y_val = create_sequences(val_data_processed, seq_len)\n",
        "\n",
        "    print(f\"Training sequences shape: {X_train.shape}\")\n",
        "    print(f\"Validation sequences shape: {X_val.shape}\")\n",
        "\n",
        "    # Log data information\n",
        "    wandb.log({\n",
        "        \"train_samples\": len(X_train),\n",
        "        \"val_samples\": len(X_val),\n",
        "        \"n_features\": X_train.shape[-1],\n",
        "        \"sequence_length\": X_train.shape[1]\n",
        "    })\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
        "    X_val_scaled = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
        "\n",
        "    # Scale targets\n",
        "    target_scaler = StandardScaler()\n",
        "    y_train_scaled = target_scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
        "    y_val_scaled = target_scaler.transform(y_val.reshape(-1, 1)).flatten()\n",
        "\n",
        "    # Convert to tensors\n",
        "    X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
        "    y_train_tensor = torch.FloatTensor(y_train_scaled)\n",
        "    X_val_tensor = torch.FloatTensor(X_val_scaled)\n",
        "    y_val_tensor = torch.FloatTensor(y_val_scaled)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize model\n",
        "    n_vars = X_train.shape[-1]  # Number of features\n",
        "    model = PatchTST(\n",
        "        n_vars=n_vars,\n",
        "        patch_len=wandb.config.patch_len,\n",
        "        stride=wandb.config.stride,\n",
        "        d_model=wandb.config.d_model,\n",
        "        n_heads=wandb.config.n_heads,\n",
        "        n_layers=wandb.config.n_layers,\n",
        "        d_ff=wandb.config.d_ff,\n",
        "        dropout=wandb.config.dropout\n",
        "    )\n",
        "\n",
        "    num_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Model initialized with {num_params} parameters\")\n",
        "\n",
        "    # Log model information\n",
        "    wandb.log({\"model_parameters\": num_params})\n",
        "\n",
        "    # Train model\n",
        "    print(\"Training model...\")\n",
        "    model = train_model(model, train_loader, val_loader,\n",
        "                       num_epochs=wandb.config.num_epochs,\n",
        "                       lr=wandb.config.learning_rate,\n",
        "                       device=device)\n",
        "\n",
        "    # Make predictions\n",
        "    print(\"Making predictions...\")\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Training predictions\n",
        "        train_preds = []\n",
        "        for batch_x, _ in train_loader:\n",
        "            batch_x = batch_x.to(device)\n",
        "            pred = model(batch_x)\n",
        "            train_preds.append(pred.cpu().numpy())\n",
        "        train_preds = np.concatenate(train_preds)\n",
        "\n",
        "        # Validation predictions\n",
        "        val_preds = []\n",
        "        for batch_x, _ in val_loader:\n",
        "            batch_x = batch_x.to(device)\n",
        "            pred = model(batch_x)\n",
        "            val_preds.append(pred.cpu().numpy())\n",
        "        val_preds = np.concatenate(val_preds)\n",
        "\n",
        "    # Inverse transform predictions\n",
        "    train_preds_original = target_scaler.inverse_transform(train_preds.reshape(-1, 1)).flatten()\n",
        "    val_preds_original = target_scaler.inverse_transform(val_preds.reshape(-1, 1)).flatten()\n",
        "\n",
        "    # Calculate weights for WMAE\n",
        "    # For training data, create weights based on IsHoliday\n",
        "    train_weights = np.ones(len(y_train))  # Default weight of 1\n",
        "    val_weights = np.ones(len(y_val))      # Default weight of 1\n",
        "\n",
        "    # You would need to align these weights with your actual holiday data\n",
        "    # For now, using equal weights as an example\n",
        "\n",
        "    # Calculate WMAE\n",
        "    train_wmae = calculate_wmae(y_train, train_preds_original, train_weights)\n",
        "    val_wmae = calculate_wmae(y_val, val_preds_original, val_weights)\n",
        "\n",
        "    # Calculate additional metrics\n",
        "    train_mae = mean_absolute_error(y_train, train_preds_original)\n",
        "    val_mae = mean_absolute_error(y_val, val_preds_original)\n",
        "\n",
        "    # Log final metrics\n",
        "    wandb.log({\n",
        "        \"final_train_wmae\": train_wmae,\n",
        "        \"final_val_wmae\": val_wmae,\n",
        "        \"final_train_mae\": train_mae,\n",
        "        \"final_val_mae\": val_mae\n",
        "    })\n",
        "\n",
        "    # Create prediction vs actual plots\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Training predictions plot\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.scatter(y_train[:1000], train_preds_original[:1000], alpha=0.5)\n",
        "    plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
        "    plt.xlabel('Actual Sales')\n",
        "    plt.ylabel('Predicted Sales')\n",
        "    plt.title('Training: Predicted vs Actual')\n",
        "\n",
        "    # Validation predictions plot\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.scatter(y_val[:1000], val_preds_original[:1000], alpha=0.5)\n",
        "    plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
        "    plt.xlabel('Actual Sales')\n",
        "    plt.ylabel('Predicted Sales')\n",
        "    plt.title('Validation: Predicted vs Actual')\n",
        "\n",
        "    # Training residuals\n",
        "    plt.subplot(2, 2, 3)\n",
        "    train_residuals = y_train[:1000] - train_preds_original[:1000]\n",
        "    plt.scatter(train_preds_original[:1000], train_residuals, alpha=0.5)\n",
        "    plt.axhline(y=0, color='r', linestyle='--')\n",
        "    plt.xlabel('Predicted Sales')\n",
        "    plt.ylabel('Residuals')\n",
        "    plt.title('Training Residuals')\n",
        "\n",
        "    # Validation residuals\n",
        "    plt.subplot(2, 2, 4)\n",
        "    val_residuals = y_val[:1000] - val_preds_original[:1000]\n",
        "    plt.scatter(val_preds_original[:1000], val_residuals, alpha=0.5)\n",
        "    plt.axhline(y=0, color='r', linestyle='--')\n",
        "    plt.xlabel('Predicted Sales')\n",
        "    plt.ylabel('Residuals')\n",
        "    plt.title('Validation Residuals')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Log the plot to wandb\n",
        "    wandb.log({\"prediction_plots\": wandb.Image(plt)})\n",
        "    plt.close()\n",
        "\n",
        "    # Create a summary table\n",
        "    summary_data = [\n",
        "        [\"Training WMAE\", train_wmae],\n",
        "        [\"Validation WMAE\", val_wmae],\n",
        "        [\"Training MAE\", train_mae],\n",
        "        [\"Validation MAE\", val_mae],\n",
        "        [\"Model Parameters\", num_params],\n",
        "        [\"Training Samples\", len(X_train)],\n",
        "        [\"Validation Samples\", len(X_val)]\n",
        "    ]\n",
        "\n",
        "    table = wandb.Table(data=summary_data, columns=[\"Metric\", \"Value\"])\n",
        "    wandb.log({\"results_summary\": table})\n",
        "\n",
        "    print(f\"\\nResults:\")\n",
        "    print(f\"Training WMAE: {train_wmae:.4f}\")\n",
        "    print(f\"Validation WMAE: {val_wmae:.4f}\")\n",
        "    print(f\"Training MAE: {train_mae:.4f}\")\n",
        "    print(f\"Validation MAE: {val_mae:.4f}\")\n",
        "\n",
        "    # Save model artifact\n",
        "    model_artifact = wandb.Artifact(\"patchtst_model\", type=\"model\")\n",
        "    torch.save(model.state_dict(), \"patchtst_model.pth\")\n",
        "    model_artifact.add_file(\"patchtst_model.pth\")\n",
        "    wandb.log_artifact(model_artifact)\n",
        "\n",
        "    # Finish wandb run\n",
        "    wandb.finish()\n",
        "\n",
        "    return model, train_wmae, val_wmae\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model, train_wmae, val_wmae = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "vNAz7VuitFFv",
        "outputId": "4577f89d-b21e-47e6-dd6a-ff9329ba3927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">patchTST-training-run</strong> at: <a href='https://wandb.ai/agasi22-free-university-of-tbilisi-/Store-Sales-Forecasting/runs/0kd53o2j' target=\"_blank\">https://wandb.ai/agasi22-free-university-of-tbilisi-/Store-Sales-Forecasting/runs/0kd53o2j</a><br> View project at: <a href='https://wandb.ai/agasi22-free-university-of-tbilisi-/Store-Sales-Forecasting' target=\"_blank\">https://wandb.ai/agasi22-free-university-of-tbilisi-/Store-Sales-Forecasting</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250706_143732-0kd53o2j/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250706_143739-ao7o1yv2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/eghib22-free-university-of-tbilisi-/store-sales-prediction/runs/ao7o1yv2' target=\"_blank\">PatchTST</a></strong> to <a href='https://wandb.ai/eghib22-free-university-of-tbilisi-/store-sales-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/eghib22-free-university-of-tbilisi-/store-sales-prediction' target=\"_blank\">https://wandb.ai/eghib22-free-university-of-tbilisi-/store-sales-prediction</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/eghib22-free-university-of-tbilisi-/store-sales-prediction/runs/ao7o1yv2' target=\"_blank\">https://wandb.ai/eghib22-free-university-of-tbilisi-/store-sales-prediction/runs/ao7o1yv2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing data...\n",
            "Creating sequences...\n",
            "Training sequences shape: (291792, 52, 17)\n",
            "Validation sequences shape: (74770, 52, 17)\n",
            "Model initialized with 131329 parameters\n",
            "Training model...\n",
            "Epoch [0/50], Train Loss: 0.8019, Val Loss: 0.7280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r9V7x8-mUu-V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}