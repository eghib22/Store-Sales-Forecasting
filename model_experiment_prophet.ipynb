{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eghib22/Store-Sales-Forecasting/blob/main/model_experiment_prophet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O9isSKo5VXQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mv \"kaggle.json\" ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls -l ~/.kaggle/\n",
        "\n",
        "!kaggle competitions download -c walmart-recruiting-store-sales-forecasting\n",
        "!unzip walmart-recruiting-store-sales-forecasting\n",
        "!unzip '*.csv.zip'\n",
        "!unzip '*.csv.zip'\n",
        "\n",
        "!pip install prophet\n",
        "!pip install -q dagshub mlflow scikit-learn joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvAyGJbZ59PZ"
      },
      "outputs": [],
      "source": [
        "import dagshub\n",
        "dagshub.init(repo_owner='eghib22', repo_name='Store-Sales-Forecasting', mlflow=True)\n",
        "\n",
        "import mlflow\n",
        "import logging\n",
        "logging.getLogger(\"cmdstanpy\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"prophet\").setLevel(logging.WARNING)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "from prophet import Prophet\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import joblib\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "features = pd.read_csv('features.csv')\n",
        "stores = pd.read_csv('stores.csv')\n",
        "\n",
        "train['Date'] = pd.to_datetime(train['Date'])\n",
        "features['Date'] = pd.to_datetime(features['Date'])\n",
        "\n",
        "df = train.merge(features, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
        "df = df.merge(stores, on='Store', how='left')\n",
        "df = df.sort_values('Date')\n",
        "\n",
        "for col in ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']:\n",
        "    df[col] = df[col].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "def weighted_mae(y_true, y_pred, weights):\n",
        "    return np.sum(weights * np.abs(y_true - y_pred)) / np.sum(weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3hTzb986FHG"
      },
      "outputs": [],
      "source": [
        "class ProphetWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=False, changepoint_prior_scale=0.5):\n",
        "        self.yearly_seasonality = yearly_seasonality\n",
        "        self.weekly_seasonality = weekly_seasonality\n",
        "        self.daily_seasonality = daily_seasonality\n",
        "        self.changepoint_prior_scale = changepoint_prior_scale\n",
        "        self.model_ = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.model_ = Prophet(\n",
        "            yearly_seasonality=self.yearly_seasonality,\n",
        "            weekly_seasonality=self.weekly_seasonality,\n",
        "            daily_seasonality=self.daily_seasonality,\n",
        "            changepoint_prior_scale=self.changepoint_prior_scale\n",
        "        )\n",
        "        self.model_.fit(X)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        forecast = self.model_.predict(X)\n",
        "        return forecast['yhat'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D3M4g7Mx6f0w"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "all_preds = []\n",
        "\n",
        "store_dept_groups = df.groupby(['Store', 'Dept'])\n",
        "total_groups = len(store_dept_groups)\n",
        "\n",
        "print(f\"--- Starting Prophet for {total_groups} Store-Dept combos ---\")\n",
        "\n",
        "mlflow.set_experiment(\"Prophet_Forecasting\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"Prophet_Improved_Seasonality_Run\"):\n",
        "    mlflow.log_param(\"model\", \"Prophet\")\n",
        "    mlflow.log_param(\"seasonality_yearly\", True)\n",
        "    mlflow.log_param(\"seasonality_weekly\", True)\n",
        "    mlflow.log_param(\"seasonality_daily\", False)\n",
        "    mlflow.log_param(\"changepoint_prior_scale\", 0.5)\n",
        "\n",
        "    for idx, ((store_id, dept_id), group) in enumerate(store_dept_groups, start=1):\n",
        "        print(f\"\\n--- Processing Store: {store_id}, Dept: {dept_id} ({idx}/{total_groups}) ---\")\n",
        "\n",
        "        g = group.sort_values('Date').copy()\n",
        "        g['ds'] = g['Date']\n",
        "        g['y'] = g['Weekly_Sales']\n",
        "        weights = g['IsHoliday'].apply(lambda x: 5 if x else 1)\n",
        "\n",
        "        y_train = g[g['ds'] < '2012-01-01']\n",
        "        y_val = g[(g['ds'] >= '2012-01-01') & (g['ds'] < '2012-07-01')]\n",
        "        weights_val = weights.loc[y_val.index]\n",
        "\n",
        "        if len(y_train) < 100 or len(y_val) < 20:\n",
        "            print(f\"   Skipped: Not enough data ({len(y_train)} train, {len(y_val)} val)\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            pipe = Pipeline([\n",
        "                ('model', ProphetWrapper(\n",
        "                    yearly_seasonality=True,\n",
        "                    weekly_seasonality=True,\n",
        "                    daily_seasonality=False,\n",
        "                    changepoint_prior_scale=0.5\n",
        "                ))\n",
        "            ])\n",
        "\n",
        "            pipe.fit(y_train[['ds', 'y']])\n",
        "            y_pred = pipe.predict(y_val[['ds']])\n",
        "\n",
        "            y_true = y_val['y'].values\n",
        "            wmae = weighted_mae(y_true, y_pred, weights_val)\n",
        "            rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "            print(f\"   WMAE: {wmae:.2f} | RMSE: {rmse:.2f}\")\n",
        "\n",
        "            results.append({\n",
        "                'Store': store_id,\n",
        "                'Dept': dept_id,\n",
        "                'RMSE': rmse,\n",
        "                'WMAE': wmae\n",
        "            })\n",
        "\n",
        "            all_preds.append(pd.DataFrame({\n",
        "                'y_true': y_true,\n",
        "                'y_pred': y_pred,\n",
        "                'weight': weights_val.values\n",
        "            }))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   Failed: {e}\")\n",
        "            continue\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "    if len(all_preds) > 0:\n",
        "        all_df = pd.concat(all_preds)\n",
        "        overall_wmae = np.sum(all_df['weight'] * np.abs(all_df['y_true'] - all_df['y_pred'])) / np.sum(all_df['weight'])\n",
        "        print(f\"\\n Overall WMAE: {overall_wmae:.2f}\")\n",
        "        mlflow.log_metric(\"Overall_WMAE\", overall_wmae)\n",
        "    else:\n",
        "        print(\"No valid predictions generated.\")\n",
        "\n",
        "    mlflow.log_metric(\"Total_StoreDept_Models\", len(results))\n",
        "\n",
        "    best_pipeline = Pipeline([\n",
        "        ('model', ProphetWrapper(\n",
        "            yearly_seasonality=True,\n",
        "            weekly_seasonality=True,\n",
        "            daily_seasonality=False,\n",
        "            changepoint_prior_scale=0.5\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    mlflow.sklearn.log_model(best_pipeline, artifact_path=\"Prophet_Pipeline\")\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv('/content/drive/MyDrive/prophet_results.csv', index=False)\n",
        "\n",
        "    print(results_df.head())\n",
        "\n",
        "print(\"Done. Model logged and saved.\")\n",
        "mlflow.end_run()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMawI+ALdX+/19RE2THZNhr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}