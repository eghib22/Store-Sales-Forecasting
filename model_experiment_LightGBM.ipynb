{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOm1Yn1Z4lK1NnhbOP1WV6b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eghib22/Store-Sales-Forecasting/blob/main/model_experiment_LightGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9OwPKteDhVm"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mv \"kaggle.json\" ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls -l ~/.kaggle/\n",
        "\n",
        "!kaggle competitions download -c walmart-recruiting-store-sales-forecasting\n",
        "!unzip walmart-recruiting-store-sales-forecasting\n",
        "!unzip '*.csv.zip'\n",
        "!unzip '*.csv.zip'\n",
        "!pip install mlflow dagshub lightgbm scikit-learn joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dagshub\n",
        "dagshub.init(repo_owner='eghib22', repo_name='Store-Sales-Forecasting', mlflow=True)\n",
        "\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import joblib\n"
      ],
      "metadata": {
        "id": "SMWjnn5dFU_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "features = pd.read_csv('features.csv')\n",
        "stores = pd.read_csv('stores.csv')\n",
        "sample_submission = pd.read_csv('sampleSubmission.csv')\n",
        "\n",
        "train['Date'] = pd.to_datetime(train['Date'])\n",
        "test['Date'] = pd.to_datetime(test['Date'])\n",
        "features['Date'] = pd.to_datetime(features['Date'])\n",
        "\n",
        "train_merged = pd.merge(train, features, on=['Store', 'Date'], how='left')\n",
        "train_merged = pd.merge(train_merged, stores, on='Store', how='left')\n",
        "\n",
        "test_merged = pd.merge(test, features, on=['Store', 'Date'], how='left')\n",
        "test_merged = pd.merge(test_merged, stores, on='Store', how='left')\n",
        "\n",
        "train_merged['Date'] = pd.to_datetime(train_merged['Date'])\n",
        "train_data = train_merged[train_merged['Date'] < '2012-01-01']\n",
        "val_data = train_merged[(train_merged['Date'] >= '2012-01-01') & (train_merged['Date'] < '2012-07-01')]\n"
      ],
      "metadata": {
        "id": "yaqsBchsFa0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df):\n",
        "    type_map = {'A': 0, 'B': 1, 'C': 2}\n",
        "    df = df.copy()\n",
        "    df['Type'] = df['Type'].map(type_map)\n",
        "    if 'IsHoliday_x' in df.columns:\n",
        "        df['IsHoliday'] = df['IsHoliday_x'].astype(int)\n",
        "        df = df.drop(columns=['IsHoliday_x', 'IsHoliday_y'])\n",
        "    elif 'IsHoliday' in df.columns:\n",
        "        df['IsHoliday'] = df['IsHoliday'].astype(int)\n",
        "    df['Year'] = df['Date'].dt.year\n",
        "    df['Month'] = df['Date'].dt.month\n",
        "    df['Week'] = df['Date'].dt.isocalendar().week\n",
        "    df['Day'] = df['Date'].dt.day\n",
        "    markdown_cols = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
        "    for col in markdown_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].fillna(0)\n",
        "    df = df.drop(columns=['Date'])\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "SDjXta3oFdfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "mlflow.set_experiment(\"LightGBM_Training\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"LightGBM_Improved_Model\"):\n",
        "    X_train = preprocess(train_data.drop(columns=['Weekly_Sales']))\n",
        "    y_train = train_data['Weekly_Sales']\n",
        "    val_data_processed = preprocess(val_data)\n",
        "    X_val = val_data_processed.drop(columns=['Weekly_Sales'])\n",
        "    y_val = val_data_processed['Weekly_Sales']\n",
        "    weights_val = val_data_processed['IsHoliday'].apply(lambda x: 5 if x else 1)\n",
        "\n",
        "    model = lgb.LGBMRegressor(\n",
        "        random_state=42,\n",
        "        n_estimators=2000,\n",
        "        learning_rate=0.015,\n",
        "        num_leaves=70,\n",
        "        max_depth=14\n",
        "    )\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocess', FunctionTransformer(preprocess)),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    wmae = np.sum(weights_val * np.abs(y_val - y_pred)) / np.sum(weights_val)\n",
        "\n",
        "    print(\"Validation RMSE:\", rmse)\n",
        "    print(\"Validation WMAE:\", wmae)\n",
        "\n",
        "    mlflow.log_param(\"n_estimators\", 2000)\n",
        "    mlflow.log_param(\"learning_rate\", 0.015)\n",
        "    mlflow.log_param(\"num_leaves\", 70)\n",
        "    mlflow.log_param(\"max_depth\", 14)\n",
        "    mlflow.log_metric(\"Validation_RMSE\", rmse)\n",
        "    mlflow.log_metric(\"Validation_WMAE\", wmae)\n",
        "\n",
        "    joblib.dump(pipeline, \"lgbm_pipeline.pkl\")\n",
        "    mlflow.log_artifact(\"lgbm_pipeline.pkl\")\n",
        "\n",
        "mlflow.end_run()\n"
      ],
      "metadata": {
        "id": "hxeIYdNnFfqV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}